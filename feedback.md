1. Overall, this is a well-organized and well-executed project. You have completed almost every instructions and spent non-trivial effort to put together this task. I hope you do learn a lot in this process. 
2. The error analysis is good and you should keep this for all subsequent iterations. The proposed strategy is a bit vague. You can try to think about questions like: does using a larger model can help? does using a different training paradigm help (RLHF)? how can you minimize the loss of content during backtranslation? are there different types of hate speech? do different types of hate speech require different remedies? To excel at the task, you need a good understanding at both the data and the model. Generally speaking, it is recommended that you try to improve based on the baseline model and change one condition at a time to see if this change can improve performance. If you don't plan to train a lot of new models, you can also try setting up `vllm` to host larger models and try prompting them to detoxify.  
3. I understand the docker issue on Tira. I will make it an optional requirement to submit to the official leaderboard. The organizer has run shared tasks for around ten years, so I believe there must be a way to resolve this. I would suggest that you reach out to the organizer or ask the question in the Tira forum. Eventually, if you want your results to count, you still need to make at least one successful submission.
